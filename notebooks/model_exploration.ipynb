{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(val):\n",
    "    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n",
    "    stops_words = set(stopwords.words(\"english\"))\n",
    "    regex = re.compile('([^\\s\\w]|_)+')\n",
    "    sentence = regex.sub('', val).lower()\n",
    "    sentence = sentence.split(\" \")\n",
    "    \n",
    "    for word in list(sentence):\n",
    "        if word in stops_words:\n",
    "            sentence.remove(word)  \n",
    "            \n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence\n",
    "\n",
    "def clean_dataframe(data):\n",
    "    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n",
    "    data = data.dropna(how=\"any\")\n",
    "    \n",
    "    for col in ['question1', 'question2']:\n",
    "        data[col] = data[col].apply(clean_sentence)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_clean = clean_dataframe(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import gc\n",
    "\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from simhash import Simhash\n",
    "\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    return data.apply(apply_func, axis=1, raw=True)\n",
    "\n",
    "def chunk(data, num):   \n",
    "    chunk_size = math.ceil(len(data) / num)\n",
    "    return [data[i*chunk_size : (i+1)*chunk_size] for i in range(num)]\n",
    "\n",
    "def pool_apply(data, proc_num=8):\n",
    "    \n",
    "    with Pool(processes=proc_num) as pool:\n",
    "        chunks = chunk(data, proc_num) \n",
    "        proccessed_chunks = list(pool.map(transform_data, chunks))\n",
    "  \n",
    "    return np.hstack(tuple(proccessed_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def word_match_share(row):\n",
    "    stops_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    \n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops_words:\n",
    "            q1words[word] = 1\n",
    "            \n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops_words:\n",
    "            q2words[word] = 1\n",
    "            \n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "def tfidf_word_match_share(row):\n",
    "    stops_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    \n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops_words:\n",
    "            q1words[word] = 1\n",
    "            \n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops_words:\n",
    "            q2words[word] = 1\n",
    "            \n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    with np.errstate(invalid='ignore'):\n",
    "        shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [\n",
    "            weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "        \n",
    "        total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "\n",
    "        R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "\n",
    "    return R if not math.isnan(R) else 0\n",
    "\n",
    "\n",
    "def start_with_same_first_word(row):\n",
    "    if not isinstance(row['question1'], str) or not isinstance(row['question2'], str):\n",
    "        return 0\n",
    "    \n",
    "    first_word_q1 = row['question1'].split()[0].lower()\n",
    "    first_word_q2 = row['question2'].split()[0].lower()\n",
    "    \n",
    "    return 1 if first_word_q1 == first_word_q2 else 0\n",
    "\n",
    "def question_length(row):\n",
    "    question = row[feature]\n",
    "    return len(question) if isinstance(question, str) else 0\n",
    "\n",
    "def word_count(row):\n",
    "    question = row[feature]\n",
    "    return len(question.split()) if isinstance(question, str) else 0\n",
    "\n",
    "\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "    \n",
    "def simhash_distance_seq(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    if not isinstance(q1, str) or not isinstance(q2, str):\n",
    "        return 0\n",
    "\n",
    "    return Simhash(q1).distance(Simhash(q2))\n",
    "\n",
    "def simhash_distance_shingle(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    if not isinstance(q1, str) or not isinstance(q2, str):\n",
    "        return 0\n",
    "    \n",
    "    q1_shingles = get_singles(q1)\n",
    "    q2_shingles = get_singles(q2)\n",
    "    \n",
    "    return Simhash(q1_shingles).distance(Simhash(q2_shingles))\n",
    "\n",
    "def get_singles(sequence, width = 3):\n",
    "    sequence = sequence.lower()\n",
    "    sequence = re.sub(r'[^\\w]+', '', sequence)\n",
    "    return [sequence[i:i + width] for i in range(max(len(sequence) - width + 1, 1))]\n",
    "\n",
    "\n",
    "\n",
    "def get_common_unigrams(row):\n",
    "    question1 = str(row['question1'])\n",
    "    question2 = str(row['question2'])\n",
    "    \n",
    "    q1_unigrams = set([i for i in nltk.ngrams(question1, 1)])\n",
    "    q2_unigrams = set([i for i in nltk.ngrams(question2, 1)])\n",
    "    return len( q1_unigrams.intersection(q2_unigrams))\n",
    "\n",
    "def get_common_unigram_ratio(row):\n",
    "    question1 = str(row['question1'])\n",
    "    question2 = str(row['question2'])\n",
    "    \n",
    "    q1_unigrams = set([i for i in nltk.ngrams(question1, 1)])\n",
    "    q2_unigrams = set([i for i in nltk.ngrams(question2, 1)])\n",
    "    unigram_count = float(row[\"unigrams_common_count\"])\n",
    "               \n",
    "    return  unigram_count / max(len(q1_unigrams.union(q2_unigrams)),1)\n",
    "\n",
    "def get_common_bigrams(row):\n",
    "    question1 = str(row['question1'])\n",
    "    question2 = str(row['question2'])\n",
    "    \n",
    "    q1_bigrams = set([i for i in nltk.ngrams(question1, 2)])\n",
    "    q2_bigrams = set([i for i in nltk.ngrams(question2, 2)])\n",
    "    return len(q1_bigrams.intersection(q2_bigrams))\n",
    "\n",
    "def get_common_bigram_ratio(row):\n",
    "    question1 = str(row['question1'])\n",
    "    question2 = str(row['question2'])\n",
    "    \n",
    "    q1_bigrams = set([i for i in nltk.ngrams(question1, 2)])\n",
    "    q2_bigrams = set([i for i in nltk.ngrams(question2, 2)])\n",
    "    bigram_count = float(row[\"bigrams_common_count\"])\n",
    "               \n",
    "    return  bigram_count / max(len(q1_bigrams.union(q2_bigrams)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eps = 5000 \n",
    "train_qs = pd.Series(train['question1'].tolist() + train['question2'].tolist()).astype(str)\n",
    "words = (\" \".join(train_qs)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train[train['is_duplicate']==1][:20][['question1', 'question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply_func always MUST be defined above pool_apply, cheers!    \n",
    "apply_func = word_match_share\n",
    "train['word_share'] = pool_apply(train)\n",
    "\n",
    "apply_func = start_with_same_first_word\n",
    "train['start_with_same_world'] = pool_apply(train)\n",
    "\n",
    "feature = 'question1'\n",
    "apply_func = question_length\n",
    "train['q1_char_num'] = pool_apply(train)\n",
    "\n",
    "feature = 'question2'\n",
    "apply_func = question_length\n",
    "train['q2_char_num'] = pool_apply(train)\n",
    "\n",
    "feature = 'question1'\n",
    "apply_func = word_count\n",
    "train['q1_word_num'] = pool_apply(train)\n",
    "\n",
    "feature = 'question2'\n",
    "apply_func = word_count\n",
    "train['q2_word_num'] = pool_apply(train)\n",
    "\n",
    "apply_func = tfidf_word_match_share\n",
    "train['rfidf_share'] = pool_apply(train)\n",
    "\n",
    "train['char_difference'] = abs(train['q1_char_num'] - train['q2_char_num'])\n",
    "train['word_difference'] = abs(train['q1_word_num'] - train['q2_word_num'])\n",
    "\n",
    "apply_func = simhash_distance_seq\n",
    "train['seq_simhash_distance'] = pool_apply(train)\n",
    "\n",
    "apply_func = simhash_distance_shingle\n",
    "train['shingle_simhash_distance'] = pool_apply(train)\n",
    "\n",
    "train['avg_word_len_q1'] = train['q1_char_num'] / (train['q1_word_num'] + 10e-4)\n",
    "train['avg_word_len_q2'] = train['q2_char_num'] / (train['q2_word_num'] + 10e-4)\n",
    "train['avg_word_difference'] = abs(train['avg_word_len_q1'] - train['avg_word_len_q2'])\n",
    "\n",
    "apply_func = get_common_unigrams\n",
    "train['unigrams_common_count'] = pool_apply(train)\n",
    "\n",
    "apply_func = get_common_bigrams\n",
    "train['bigrams_common_count'] = pool_apply(train)\n",
    "\n",
    "apply_func = get_common_unigram_ratio\n",
    "train['unigrams_common_ratio'] = pool_apply(train)\n",
    "\n",
    "apply_func = get_common_bigram_ratio\n",
    "train['bigrams_common_ratio'] = pool_apply(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "apply_func = start_with_same_first_word\n",
    "test['start_with_same_world'] = pool_apply(test)\n",
    "\n",
    "apply_func = word_match_share\n",
    "test['word_share'] = pool_apply(test)\n",
    "\n",
    "feature = 'question1'\n",
    "apply_func = question_length\n",
    "test['q1_char_num'] = pool_apply(test)\n",
    "\n",
    "feature = 'question2'\n",
    "apply_func = question_length\n",
    "test['q2_char_num'] = pool_apply(test)\n",
    "\n",
    "feature = 'question1'\n",
    "apply_func = word_count\n",
    "test['q1_word_num'] = pool_apply(test)\n",
    "\n",
    "feature = 'question2'\n",
    "apply_func = word_count\n",
    "test['q2_word_num'] = pool_apply(test)\n",
    "\n",
    "apply_func = tfidf_word_match_share\n",
    "test['rfidf_share'] = pool_apply(test)\n",
    "\n",
    "test['char_difference'] = abs(test['q1_char_num'] - test['q2_char_num'])\n",
    "test['word_difference'] = abs(test['q1_word_num'] - test['q2_word_num'])\n",
    "\n",
    "apply_func = simhash_distance_seq\n",
    "test['seq_simhash_distance'] = pool_apply(test)\n",
    "\n",
    "apply_func = simhash_distance_shingle\n",
    "test['shingle_simhash_distance'] = pool_apply(test)\n",
    "\n",
    "apply_func = simhash_distance_seq\n",
    "test['seq_simhash_distance'] = pool_apply(test)\n",
    "\n",
    "apply_func = simhash_distance_shingle\n",
    "test['shingle_simhash_distance'] = pool_apply(test)\n",
    "\n",
    "test['avg_word_len_q1'] = test['q1_char_num'] / (test['q1_word_num'] + 10e-4)\n",
    "test['avg_word_len_q2'] = test['q2_char_num'] / (test['q2_word_num'] + 10e-4)\n",
    "test['avg_word_difference'] = abs(test['avg_word_len_q1'] - test['avg_word_len_q2'])\n",
    "\n",
    "apply_func = get_common_unigrams\n",
    "test['unigrams_common_count'] = pool_apply(test)\n",
    "\n",
    "apply_func = get_common_bigrams\n",
    "test['bigrams_common_count'] = pool_apply(test)\n",
    "\n",
    "apply_func = get_common_unigram_ratio\n",
    "test['unigrams_common_ratio'] = pool_apply(test)\n",
    "\n",
    "apply_func = get_common_bigram_ratio\n",
    "test['bigrams_common_ratio'] = pool_apply(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>word_share</th>\n",
       "      <th>start_with_same_world</th>\n",
       "      <th>q1_char_num</th>\n",
       "      <th>q2_char_num</th>\n",
       "      <th>q1_word_num</th>\n",
       "      <th>q2_word_num</th>\n",
       "      <th>rfidf_share</th>\n",
       "      <th>char_difference</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>seq_simhash_distance</th>\n",
       "      <th>shingle_simhash_distance</th>\n",
       "      <th>avg_word_len_q1</th>\n",
       "      <th>avg_word_len_q2</th>\n",
       "      <th>avg_word_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4.713949</td>\n",
       "      <td>4.749604</td>\n",
       "      <td>0.035655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>6.374203</td>\n",
       "      <td>6.768710</td>\n",
       "      <td>0.394507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.355191</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>5.213913</td>\n",
       "      <td>5.899410</td>\n",
       "      <td>0.685497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>4.545041</td>\n",
       "      <td>7.221420</td>\n",
       "      <td>2.676378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>5.845704</td>\n",
       "      <td>5.570633</td>\n",
       "      <td>0.275071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "   word_share  start_with_same_world  q1_char_num  q2_char_num  q1_word_num  \\\n",
       "0    0.727273                      1           66           57           14   \n",
       "1    0.307692                      1           51           88            8   \n",
       "2    0.363636                      1           73           59           14   \n",
       "3    0.000000                      0           50           65           11   \n",
       "4    0.000000                      1           76           39           13   \n",
       "\n",
       "   q2_word_num  rfidf_share  char_difference  word_difference  \\\n",
       "0           12     0.772164                9                2   \n",
       "1           13     0.361758               37                5   \n",
       "2           10     0.355191               14                4   \n",
       "3            9     0.000000               15                2   \n",
       "4            7     0.000000               37                6   \n",
       "\n",
       "   seq_simhash_distance  shingle_simhash_distance  avg_word_len_q1  \\\n",
       "0                    15                        10         4.713949   \n",
       "1                    22                        18         6.374203   \n",
       "2                    26                        23         5.213913   \n",
       "3                    36                        28         4.545041   \n",
       "4                    34                        21         5.845704   \n",
       "\n",
       "   avg_word_len_q2  avg_word_difference  \n",
       "0         4.749604             0.035655  \n",
       "1         6.768710             0.394507  \n",
       "2         5.899410             0.685497  \n",
       "3         7.221420             2.676378  \n",
       "4         5.570633             0.275071  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>start_with_same_world</th>\n",
       "      <th>word_share</th>\n",
       "      <th>q1_char_num</th>\n",
       "      <th>q2_char_num</th>\n",
       "      <th>q1_word_num</th>\n",
       "      <th>q2_word_num</th>\n",
       "      <th>rfidf_share</th>\n",
       "      <th>char_difference</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>seq_simhash_distance</th>\n",
       "      <th>shingle_simhash_distance</th>\n",
       "      <th>avg_word_len_q1</th>\n",
       "      <th>avg_word_len_q2</th>\n",
       "      <th>avg_word_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>5.181347</td>\n",
       "      <td>4.856796</td>\n",
       "      <td>0.324551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>4.713949</td>\n",
       "      <td>6.141980</td>\n",
       "      <td>1.428031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.468893</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>4.285408</td>\n",
       "      <td>4.832528</td>\n",
       "      <td>0.547120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>6.748313</td>\n",
       "      <td>5.664778</td>\n",
       "      <td>1.083535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>7.998000</td>\n",
       "      <td>4.999167</td>\n",
       "      <td>2.998834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  start_with_same_world  \\\n",
       "0  Why did Microsoft choose core m3 and not core ...                      0   \n",
       "1        How much cost does hair transplant require?                      0   \n",
       "2                      What you send money to China?                      1   \n",
       "3                                  What foods fibre?                      0   \n",
       "4                     How their can I start reading?                      1   \n",
       "\n",
       "   word_share  q1_char_num  q2_char_num  q1_word_num  q2_word_num  \\\n",
       "0    0.266667           57           68           11           14   \n",
       "1    0.500000           66           43           14            7   \n",
       "2    0.444444           60           29           14            6   \n",
       "3    0.000000           27           17            4            3   \n",
       "4    0.800000           32           30            4            6   \n",
       "\n",
       "   rfidf_share  char_difference  word_difference  seq_simhash_distance  \\\n",
       "0     0.274019               11                3                    26   \n",
       "1     0.480962               23                7                    27   \n",
       "2     0.468893               31                8                    22   \n",
       "3     0.000000               10                1                    32   \n",
       "4     1.000000                2                2                    21   \n",
       "\n",
       "   shingle_simhash_distance  avg_word_len_q1  avg_word_len_q2  \\\n",
       "0                        23         5.181347         4.856796   \n",
       "1                        22         4.713949         6.141980   \n",
       "2                        27         4.285408         4.832528   \n",
       "3                        33         6.748313         5.664778   \n",
       "4                        23         7.998000         4.999167   \n",
       "\n",
       "   avg_word_difference  \n",
       "0             0.324551  \n",
       "1             1.428031  \n",
       "2             0.547120  \n",
       "3             1.083535  \n",
       "4             2.998834  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus.reader.wordnet import ADJ, ADJ_SAT, ADV, NOUN, VERB\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_corpus(data):\n",
    "    \"Creates a list of lists containing words from each sentence\"\n",
    "    corpus = []\n",
    "    for col in ['question1', 'question2']:\n",
    "        for sentence in data[col].iteritems():\n",
    "            word_list = sentence[1].split(\" \")\n",
    "            corpus.append(word_list)\n",
    "            \n",
    "    return corpus\n",
    "\n",
    "corpus = build_corpus(train_clean)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5423857 , -0.18877243, -0.69895309, -1.62728703, -0.03071801,\n",
       "        0.92019987,  2.66838503,  0.26456219,  1.01132786,  0.65255654,\n",
       "        1.51943994,  0.34171048, -0.60262084, -3.05914187, -2.49309993,\n",
       "        2.32025671,  0.55832887, -2.12868094, -1.48019063,  0.26215437,\n",
       "        0.87051916,  0.53066379, -1.2863183 , -0.62387747, -2.58575153,\n",
       "        0.26904136,  2.88699746, -3.03885865,  0.3766177 , -2.54019713,\n",
       "       -0.25186637,  1.73393941,  2.31052351,  1.37149477,  0.81612736,\n",
       "        1.0461694 ,  0.00594117, -1.76909316,  0.27269265,  0.53426611,\n",
       "        0.26753989, -1.60441387, -0.30379802,  2.01264501, -2.93228245,\n",
       "       -0.12985253,  3.03247499,  2.15053654, -0.55543244,  3.65650511,\n",
       "       -0.55203521,  4.95813894,  0.16183898, -1.47227442, -1.03181267,\n",
       "       -2.21922421,  0.92020571,  3.44367146, -3.06644678, -2.15232968,\n",
       "        1.71454263,  2.65542889,  0.73848563,  1.55730188,  2.12465954,\n",
       "        2.60739946, -2.69158435, -2.13815713,  1.95312846,  0.75385427,\n",
       "        3.37815142,  2.63283253, -0.41845337, -3.23039794, -1.3704952 ,\n",
       "       -0.68865907,  2.88301754,  1.8310523 , -2.04978561, -1.98131979,\n",
       "        0.45061508,  0.98055398, -2.08166742,  1.38812017, -3.12347269,\n",
       "        2.7007184 ,  1.33209383, -0.9563545 ,  1.78830063, -0.31514627,\n",
       "       -0.1157185 ,  0.40682772,  0.49799928,  1.50374353,  2.48315978,\n",
       "        1.5400908 ,  0.02280473,  0.11039966, -1.58231175,  1.57306325], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\n",
    "word2vec_model.wv['trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv['question']\n",
    "\n",
    "'question' in word2vec_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def question_to_word2vec(question_string, word2vec_model):\n",
    "    \"\"\"\n",
    "    Given question string, returns word2vec vector of the questions tring\n",
    "    :param question_string : The given question as a string.\n",
    "    \"\"\"\n",
    "    stops_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    if not isinstance(question_string, str):\n",
    "        return 0\n",
    "    \n",
    "    words = word_tokenize(question_string)[:-1]\n",
    "    non_stop_words = []\n",
    "    for word in words:\n",
    "        if word.lower().strip('-') not in stops_words:\n",
    "            word = WordNetLemmatizer().lemmatize(word, NOUN)\n",
    "            \n",
    "            if word.lower() in word2vec_model.wv:\n",
    "                non_stop_words.append(word.lower().strip('-'))\n",
    "            \n",
    "    if len(non_stop_words) == 0:\n",
    "        return 0\n",
    "    \n",
    "    vectors = [word2vec_model.wv[word] for word in non_stop_words]\n",
    "    vector = sum(vectors)/float(len(non_stop_words))\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def numpy_cosine(row):\n",
    "    \"\"\"\n",
    "    Cosine similarity between q1 and q2 question instances using their vectors\n",
    "    :return: similarity between q1 and q2\n",
    "    \"\"\"\n",
    "    q1, q2 = row['question1'], row['question2']\n",
    "    q1_vec, q2_vec = question_to_word2vec(q1, word2vec_model), question_to_word2vec(q2, word2vec_model)\n",
    "    \n",
    "    with np.errstate(invalid='ignore'):\n",
    "        cosine_similarity = np.dot(q1_vec, q2_vec) / (np.linalg.norm(q1_vec) * np.linalg.norm(q2_vec))\n",
    "    \n",
    "    return cosine_similarity if isinstance(cosine_similarity, np.float32) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "apply_func = numpy_cosine\n",
    "train['cosin_sim'] = pool_apply(train, proc_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apply_func = numpy_cosine\n",
    "test['cosin_sim'] = pool_apply(test, proc_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>word_share</th>\n",
       "      <th>start_with_same_world</th>\n",
       "      <th>q1_char_num</th>\n",
       "      <th>q2_char_num</th>\n",
       "      <th>...</th>\n",
       "      <th>q2_word_num</th>\n",
       "      <th>rfidf_share</th>\n",
       "      <th>char_difference</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>seq_simhash_distance</th>\n",
       "      <th>shingle_simhash_distance</th>\n",
       "      <th>avg_word_len_q1</th>\n",
       "      <th>avg_word_len_q2</th>\n",
       "      <th>avg_word_difference</th>\n",
       "      <th>cosin_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>How do we prepare for UPSC?</td>\n",
       "      <td>How do I prepare for civil service?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.328275</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>4.499250</td>\n",
       "      <td>4.999286</td>\n",
       "      <td>0.500036</td>\n",
       "      <td>0.780258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>What is the stall speed and AOA of an f-14 wit...</td>\n",
       "      <td>Why did aircraft stop using variable-sweep win...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>4.733018</td>\n",
       "      <td>5.999500</td>\n",
       "      <td>1.266482</td>\n",
       "      <td>0.240071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>Why do Slavs squat?</td>\n",
       "      <td>Will squats make my legs thicker?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>4.748813</td>\n",
       "      <td>5.499083</td>\n",
       "      <td>0.750271</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "38  38    77    78                        How do we prepare for UPSC?   \n",
       "39  39    79    80  What is the stall speed and AOA of an f-14 wit...   \n",
       "40  40    81    82                                Why do Slavs squat?   \n",
       "\n",
       "                                            question2  is_duplicate  \\\n",
       "38                How do I prepare for civil service?             1   \n",
       "39  Why did aircraft stop using variable-sweep win...             0   \n",
       "40                  Will squats make my legs thicker?             0   \n",
       "\n",
       "    word_share  start_with_same_world  q1_char_num  q2_char_num    ...      \\\n",
       "38         0.4                      1           27           35    ...       \n",
       "39         0.0                      0           71           72    ...       \n",
       "40         0.0                      0           19           33    ...       \n",
       "\n",
       "    q2_word_num  rfidf_share  char_difference  word_difference  \\\n",
       "38            7     0.328275                8                1   \n",
       "39           12     0.000000                1                3   \n",
       "40            6     0.000000               14                2   \n",
       "\n",
       "    seq_simhash_distance  shingle_simhash_distance  avg_word_len_q1  \\\n",
       "38                    20                        21         4.499250   \n",
       "39                    42                        35         4.733018   \n",
       "40                    21                        33         4.748813   \n",
       "\n",
       "    avg_word_len_q2  avg_word_difference  cosin_sim  \n",
       "38         4.999286             0.500036   0.780258  \n",
       "39         5.999500             1.266482   0.240071  \n",
       "40         5.499083             0.750271   0.000000  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[38:41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#features = ['cosin_sim', 'word_share', 'q1_char_num', 'q1_word_num', 'q2_char_num', 'q2_word_num',\n",
    "#            'start_with_same_world', 'rfidf_share']\n",
    "\n",
    "features = ['cosin_sim', 'word_share', 'q1_char_num', 'q1_word_num', 'q2_char_num', 'q2_word_num',\n",
    "            'start_with_same_world', 'rfidf_share', 'char_difference', 'word_difference',\n",
    "           'seq_simhash_distance', 'shingle_simhash_distance', 'avg_word_len_q1', 'avg_word_len_q2',\n",
    "           'avg_word_difference', 'unigrams_common_count', 'bigrams_common_count', 'unigrams_common_ratio',\n",
    "           'bigrams_common_ratio']\n",
    "\n",
    "#features = ['cosin_sim', 'start_with_same_world', 'rfidf_share']\n",
    "\n",
    "target = 'is_duplicate'\n",
    "\n",
    "X = train[features]\n",
    "y = train[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19124366100096607\n"
     ]
    }
   ],
   "source": [
    "pos_train = X[y == 1]\n",
    "neg_train = X[y == 0]\n",
    "\n",
    "# Now we oversample the negative class\n",
    "# There is likely a much more elegant way to do this...\n",
    "p = 0.165\n",
    "scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "while scale > 1:\n",
    "    neg_train = pd.concat([neg_train, neg_train])\n",
    "    scale -=1\n",
    "neg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "print(len(pos_train) / (len(pos_train) + len(neg_train)))\n",
    "\n",
    "X = pd.concat([pos_train, neg_train])\n",
    "y = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_vald, y_train, y_vald = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosin_sim</th>\n",
       "      <th>word_share</th>\n",
       "      <th>q1_char_num</th>\n",
       "      <th>q1_word_num</th>\n",
       "      <th>q2_char_num</th>\n",
       "      <th>q2_word_num</th>\n",
       "      <th>start_with_same_world</th>\n",
       "      <th>rfidf_share</th>\n",
       "      <th>char_difference</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>seq_simhash_distance</th>\n",
       "      <th>shingle_simhash_distance</th>\n",
       "      <th>avg_word_len_q1</th>\n",
       "      <th>avg_word_len_q2</th>\n",
       "      <th>avg_word_difference</th>\n",
       "      <th>unigrams_common_count</th>\n",
       "      <th>bigrams_common_count</th>\n",
       "      <th>unigrams_common_ratio</th>\n",
       "      <th>bigrams_common_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109330</th>\n",
       "      <td>0.622394</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>6.832195</td>\n",
       "      <td>3.999636</td>\n",
       "      <td>2.832558</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.228070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149537</th>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>6.368086</td>\n",
       "      <td>5.582868</td>\n",
       "      <td>0.785218</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.210084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235896</th>\n",
       "      <td>0.593747</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>181</td>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190338</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>5.171281</td>\n",
       "      <td>5.302870</td>\n",
       "      <td>0.131589</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346102</th>\n",
       "      <td>0.702948</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>4.713612</td>\n",
       "      <td>5.249344</td>\n",
       "      <td>0.535731</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42793</th>\n",
       "      <td>-0.221622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>6.832764</td>\n",
       "      <td>5.999250</td>\n",
       "      <td>0.833514</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.118280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cosin_sim  word_share  q1_char_num  q1_word_num  q2_char_num  \\\n",
       "109330   0.622394    0.222222           41            6           44   \n",
       "149537   0.056752    0.000000          121           19           67   \n",
       "235896   0.593747    0.162162          181           35          175   \n",
       "346102   0.702948    0.500000           33            7           42   \n",
       "42793   -0.221622    0.000000           82           12           48   \n",
       "\n",
       "        q2_word_num  start_with_same_world  rfidf_share  char_difference  \\\n",
       "109330           11                      0     0.091403                3   \n",
       "149537           12                      0     0.000000               54   \n",
       "235896           33                      1     0.190338                6   \n",
       "346102            8                      0     0.526688                9   \n",
       "42793             8                      0     0.000000               34   \n",
       "\n",
       "        word_difference  seq_simhash_distance  shingle_simhash_distance  \\\n",
       "109330                5                    30                        31   \n",
       "149537                7                    35                        35   \n",
       "235896                2                    34                        25   \n",
       "346102                1                    27                        26   \n",
       "42793                 4                    34                        32   \n",
       "\n",
       "        avg_word_len_q1  avg_word_len_q2  avg_word_difference  \\\n",
       "109330         6.832195         3.999636             2.832558   \n",
       "149537         6.368086         5.582868             0.785218   \n",
       "235896         5.171281         5.302870             0.131589   \n",
       "346102         4.713612         5.249344             0.535731   \n",
       "42793          6.832764         5.999250             0.833514   \n",
       "\n",
       "        unigrams_common_count  bigrams_common_count  unigrams_common_ratio  \\\n",
       "109330                     11                    13               0.523810   \n",
       "149537                     17                    25               0.586207   \n",
       "235896                     27                    57               0.750000   \n",
       "346102                     10                    14               0.454545   \n",
       "42793                      17                    11               0.629630   \n",
       "\n",
       "        bigrams_common_ratio  \n",
       "109330              0.228070  \n",
       "149537              0.210084  \n",
       "235896              0.360759  \n",
       "346102              0.291667  \n",
       "42793               0.118280  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosin_sim</th>\n",
       "      <th>word_share</th>\n",
       "      <th>q1_char_num</th>\n",
       "      <th>q1_word_num</th>\n",
       "      <th>q2_char_num</th>\n",
       "      <th>q2_word_num</th>\n",
       "      <th>start_with_same_world</th>\n",
       "      <th>rfidf_share</th>\n",
       "      <th>char_difference</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>seq_simhash_distance</th>\n",
       "      <th>shingle_simhash_distance</th>\n",
       "      <th>avg_word_len_q1</th>\n",
       "      <th>avg_word_len_q2</th>\n",
       "      <th>avg_word_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686881</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>5.181347</td>\n",
       "      <td>4.856796</td>\n",
       "      <td>0.324551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741746</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>4.713949</td>\n",
       "      <td>6.141980</td>\n",
       "      <td>1.428031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837249</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468893</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>4.285408</td>\n",
       "      <td>4.832528</td>\n",
       "      <td>0.547120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>6.748313</td>\n",
       "      <td>5.664778</td>\n",
       "      <td>1.083535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>7.998000</td>\n",
       "      <td>4.999167</td>\n",
       "      <td>2.998834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cosin_sim  word_share  q1_char_num  q1_word_num  q2_char_num  q2_word_num  \\\n",
       "0   0.686881    0.266667           57           11           68           14   \n",
       "1   0.741746    0.500000           66           14           43            7   \n",
       "2   0.837249    0.444444           60           14           29            6   \n",
       "3   1.000000    0.000000           27            4           17            3   \n",
       "4   1.000000    0.800000           32            4           30            6   \n",
       "\n",
       "   start_with_same_world  rfidf_share  char_difference  word_difference  \\\n",
       "0                      0     0.274019               11                3   \n",
       "1                      0     0.480962               23                7   \n",
       "2                      1     0.468893               31                8   \n",
       "3                      0     0.000000               10                1   \n",
       "4                      1     1.000000                2                2   \n",
       "\n",
       "   seq_simhash_distance  shingle_simhash_distance  avg_word_len_q1  \\\n",
       "0                    26                        23         5.181347   \n",
       "1                    27                        22         4.713949   \n",
       "2                    22                        27         4.285408   \n",
       "3                    32                        33         6.748313   \n",
       "4                    21                        23         7.998000   \n",
       "\n",
       "   avg_word_len_q2  avg_word_difference  \n",
       "0         4.856796             0.324551  \n",
       "1         6.141980             1.428031  \n",
       "2         4.832528             0.547120  \n",
       "3         5.664778             1.083535  \n",
       "4         4.999167             2.998834  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[features]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Transofmrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model works fine without scaling\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_vald_scaled = scaler.transform(X_vald)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "#import lightgbm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_1 error hasn't decreased in 50 rounds.\n",
      "[0]\tvalidation_0-logloss:0.684018\tvalidation_1-logloss:0.683936\n",
      "[1]\tvalidation_0-logloss:0.674575\tvalidation_1-logloss:0.674483\n",
      "[2]\tvalidation_0-logloss:0.665092\tvalidation_1-logloss:0.665085\n",
      "[3]\tvalidation_0-logloss:0.656351\tvalidation_1-logloss:0.656311\n",
      "[4]\tvalidation_0-logloss:0.647597\tvalidation_1-logloss:0.647604\n",
      "[5]\tvalidation_0-logloss:0.639303\tvalidation_1-logloss:0.639205\n",
      "[6]\tvalidation_0-logloss:0.631464\tvalidation_1-logloss:0.631371\n",
      "[7]\tvalidation_0-logloss:0.623993\tvalidation_1-logloss:0.623850\n",
      "[8]\tvalidation_0-logloss:0.616406\tvalidation_1-logloss:0.616323\n",
      "[9]\tvalidation_0-logloss:0.609289\tvalidation_1-logloss:0.609031\n",
      "[10]\tvalidation_0-logloss:0.602391\tvalidation_1-logloss:0.602252\n",
      "[11]\tvalidation_0-logloss:0.595698\tvalidation_1-logloss:0.595445\n",
      "[12]\tvalidation_0-logloss:0.589066\tvalidation_1-logloss:0.588886\n",
      "[13]\tvalidation_0-logloss:0.582652\tvalidation_1-logloss:0.582478\n",
      "[14]\tvalidation_0-logloss:0.577092\tvalidation_1-logloss:0.576872\n",
      "[15]\tvalidation_0-logloss:0.571765\tvalidation_1-logloss:0.571544\n",
      "[16]\tvalidation_0-logloss:0.567031\tvalidation_1-logloss:0.566753\n",
      "[17]\tvalidation_0-logloss:0.561379\tvalidation_1-logloss:0.561109\n",
      "[18]\tvalidation_0-logloss:0.556108\tvalidation_1-logloss:0.555839\n",
      "[19]\tvalidation_0-logloss:0.550769\tvalidation_1-logloss:0.550493\n",
      "[20]\tvalidation_0-logloss:0.545607\tvalidation_1-logloss:0.545321\n",
      "[21]\tvalidation_0-logloss:0.540646\tvalidation_1-logloss:0.540337\n",
      "[22]\tvalidation_0-logloss:0.535814\tvalidation_1-logloss:0.535485\n",
      "[23]\tvalidation_0-logloss:0.531132\tvalidation_1-logloss:0.530788\n",
      "[24]\tvalidation_0-logloss:0.526581\tvalidation_1-logloss:0.526223\n",
      "[25]\tvalidation_0-logloss:0.522127\tvalidation_1-logloss:0.521787\n",
      "[26]\tvalidation_0-logloss:0.517832\tvalidation_1-logloss:0.517498\n",
      "[27]\tvalidation_0-logloss:0.513673\tvalidation_1-logloss:0.513317\n",
      "[28]\tvalidation_0-logloss:0.509832\tvalidation_1-logloss:0.509455\n",
      "[29]\tvalidation_0-logloss:0.505901\tvalidation_1-logloss:0.505501\n",
      "[30]\tvalidation_0-logloss:0.502049\tvalidation_1-logloss:0.501666\n",
      "[31]\tvalidation_0-logloss:0.498520\tvalidation_1-logloss:0.498132\n",
      "[32]\tvalidation_0-logloss:0.495421\tvalidation_1-logloss:0.494998\n",
      "[33]\tvalidation_0-logloss:0.491920\tvalidation_1-logloss:0.491486\n",
      "[34]\tvalidation_0-logloss:0.488490\tvalidation_1-logloss:0.488044\n",
      "[35]\tvalidation_0-logloss:0.485106\tvalidation_1-logloss:0.484663\n",
      "[36]\tvalidation_0-logloss:0.481879\tvalidation_1-logloss:0.481402\n",
      "[37]\tvalidation_0-logloss:0.478667\tvalidation_1-logloss:0.478215\n",
      "[38]\tvalidation_0-logloss:0.475758\tvalidation_1-logloss:0.475287\n",
      "[39]\tvalidation_0-logloss:0.472780\tvalidation_1-logloss:0.472300\n",
      "[40]\tvalidation_0-logloss:0.469877\tvalidation_1-logloss:0.469378\n",
      "[41]\tvalidation_0-logloss:0.467015\tvalidation_1-logloss:0.466535\n",
      "[42]\tvalidation_0-logloss:0.464240\tvalidation_1-logloss:0.463735\n",
      "[43]\tvalidation_0-logloss:0.461578\tvalidation_1-logloss:0.461057\n",
      "[44]\tvalidation_0-logloss:0.459083\tvalidation_1-logloss:0.458581\n",
      "[45]\tvalidation_0-logloss:0.456550\tvalidation_1-logloss:0.456009\n",
      "[46]\tvalidation_0-logloss:0.454070\tvalidation_1-logloss:0.453519\n",
      "[47]\tvalidation_0-logloss:0.451598\tvalidation_1-logloss:0.451063\n",
      "[48]\tvalidation_0-logloss:0.449216\tvalidation_1-logloss:0.448691\n",
      "[49]\tvalidation_0-logloss:0.446919\tvalidation_1-logloss:0.446368\n",
      "[50]\tvalidation_0-logloss:0.444815\tvalidation_1-logloss:0.444247\n",
      "[51]\tvalidation_0-logloss:0.442581\tvalidation_1-logloss:0.442049\n",
      "[52]\tvalidation_0-logloss:0.440469\tvalidation_1-logloss:0.439912\n",
      "[53]\tvalidation_0-logloss:0.438533\tvalidation_1-logloss:0.437970\n",
      "[54]\tvalidation_0-logloss:0.436512\tvalidation_1-logloss:0.435943\n",
      "[55]\tvalidation_0-logloss:0.434531\tvalidation_1-logloss:0.433945\n",
      "[56]\tvalidation_0-logloss:0.432716\tvalidation_1-logloss:0.432147\n",
      "[57]\tvalidation_0-logloss:0.430823\tvalidation_1-logloss:0.430277\n",
      "[58]\tvalidation_0-logloss:0.428960\tvalidation_1-logloss:0.428398\n",
      "[59]\tvalidation_0-logloss:0.427145\tvalidation_1-logloss:0.426574\n",
      "[60]\tvalidation_0-logloss:0.425387\tvalidation_1-logloss:0.424796\n",
      "[61]\tvalidation_0-logloss:0.423679\tvalidation_1-logloss:0.423083\n",
      "[62]\tvalidation_0-logloss:0.421973\tvalidation_1-logloss:0.421388\n",
      "[63]\tvalidation_0-logloss:0.420340\tvalidation_1-logloss:0.419760\n",
      "[64]\tvalidation_0-logloss:0.418777\tvalidation_1-logloss:0.418179\n",
      "[65]\tvalidation_0-logloss:0.417148\tvalidation_1-logloss:0.416590\n",
      "[66]\tvalidation_0-logloss:0.415666\tvalidation_1-logloss:0.415058\n",
      "[67]\tvalidation_0-logloss:0.414138\tvalidation_1-logloss:0.413568\n",
      "[68]\tvalidation_0-logloss:0.412695\tvalidation_1-logloss:0.412103\n",
      "[69]\tvalidation_0-logloss:0.411231\tvalidation_1-logloss:0.410672\n",
      "[70]\tvalidation_0-logloss:0.409894\tvalidation_1-logloss:0.409291\n",
      "[71]\tvalidation_0-logloss:0.408787\tvalidation_1-logloss:0.408191\n",
      "[72]\tvalidation_0-logloss:0.407432\tvalidation_1-logloss:0.406862\n",
      "[73]\tvalidation_0-logloss:0.406148\tvalidation_1-logloss:0.405551\n",
      "[74]\tvalidation_0-logloss:0.404994\tvalidation_1-logloss:0.404418\n",
      "[75]\tvalidation_0-logloss:0.403772\tvalidation_1-logloss:0.403201\n",
      "[76]\tvalidation_0-logloss:0.402680\tvalidation_1-logloss:0.402110\n",
      "[77]\tvalidation_0-logloss:0.401613\tvalidation_1-logloss:0.401035\n",
      "[78]\tvalidation_0-logloss:0.400459\tvalidation_1-logloss:0.399877\n",
      "[79]\tvalidation_0-logloss:0.399296\tvalidation_1-logloss:0.398744\n",
      "[80]\tvalidation_0-logloss:0.398186\tvalidation_1-logloss:0.397631\n",
      "[81]\tvalidation_0-logloss:0.397324\tvalidation_1-logloss:0.396764\n",
      "[82]\tvalidation_0-logloss:0.396274\tvalidation_1-logloss:0.395718\n",
      "[83]\tvalidation_0-logloss:0.395267\tvalidation_1-logloss:0.394718\n",
      "[84]\tvalidation_0-logloss:0.394254\tvalidation_1-logloss:0.393694\n",
      "[85]\tvalidation_0-logloss:0.393294\tvalidation_1-logloss:0.392734\n",
      "[86]\tvalidation_0-logloss:0.392413\tvalidation_1-logloss:0.391855\n",
      "[87]\tvalidation_0-logloss:0.391460\tvalidation_1-logloss:0.390902\n",
      "[88]\tvalidation_0-logloss:0.390551\tvalidation_1-logloss:0.390000\n",
      "[89]\tvalidation_0-logloss:0.389634\tvalidation_1-logloss:0.389087\n",
      "[90]\tvalidation_0-logloss:0.388735\tvalidation_1-logloss:0.388172\n",
      "[91]\tvalidation_0-logloss:0.387936\tvalidation_1-logloss:0.387375\n",
      "[92]\tvalidation_0-logloss:0.387099\tvalidation_1-logloss:0.386506\n",
      "[93]\tvalidation_0-logloss:0.386365\tvalidation_1-logloss:0.385770\n",
      "[94]\tvalidation_0-logloss:0.385533\tvalidation_1-logloss:0.384946\n",
      "[95]\tvalidation_0-logloss:0.384726\tvalidation_1-logloss:0.384162\n",
      "[96]\tvalidation_0-logloss:0.383929\tvalidation_1-logloss:0.383367\n",
      "[97]\tvalidation_0-logloss:0.383180\tvalidation_1-logloss:0.382609\n",
      "[98]\tvalidation_0-logloss:0.382630\tvalidation_1-logloss:0.382032\n",
      "[99]\tvalidation_0-logloss:0.381884\tvalidation_1-logloss:0.381313\n",
      "[100]\tvalidation_0-logloss:0.381158\tvalidation_1-logloss:0.380587\n",
      "[101]\tvalidation_0-logloss:0.380496\tvalidation_1-logloss:0.379896\n",
      "[102]\tvalidation_0-logloss:0.379805\tvalidation_1-logloss:0.379217\n",
      "[103]\tvalidation_0-logloss:0.379111\tvalidation_1-logloss:0.378558\n",
      "[104]\tvalidation_0-logloss:0.378455\tvalidation_1-logloss:0.377892\n",
      "[105]\tvalidation_0-logloss:0.377822\tvalidation_1-logloss:0.377238\n",
      "[106]\tvalidation_0-logloss:0.377175\tvalidation_1-logloss:0.376626\n",
      "[107]\tvalidation_0-logloss:0.376593\tvalidation_1-logloss:0.376003\n",
      "[108]\tvalidation_0-logloss:0.376041\tvalidation_1-logloss:0.375469\n",
      "[109]\tvalidation_0-logloss:0.375463\tvalidation_1-logloss:0.374901\n",
      "[110]\tvalidation_0-logloss:0.374899\tvalidation_1-logloss:0.374309\n",
      "[111]\tvalidation_0-logloss:0.374361\tvalidation_1-logloss:0.373811\n",
      "[112]\tvalidation_0-logloss:0.373842\tvalidation_1-logloss:0.373246\n",
      "[113]\tvalidation_0-logloss:0.373266\tvalidation_1-logloss:0.372708\n",
      "[114]\tvalidation_0-logloss:0.372798\tvalidation_1-logloss:0.372239\n",
      "[115]\tvalidation_0-logloss:0.372292\tvalidation_1-logloss:0.371740\n",
      "[116]\tvalidation_0-logloss:0.371768\tvalidation_1-logloss:0.371230\n",
      "[117]\tvalidation_0-logloss:0.371356\tvalidation_1-logloss:0.370806\n",
      "[118]\tvalidation_0-logloss:0.370918\tvalidation_1-logloss:0.370391\n",
      "[119]\tvalidation_0-logloss:0.370458\tvalidation_1-logloss:0.369919\n",
      "[120]\tvalidation_0-logloss:0.369984\tvalidation_1-logloss:0.369465\n",
      "[121]\tvalidation_0-logloss:0.369570\tvalidation_1-logloss:0.369041\n",
      "[122]\tvalidation_0-logloss:0.369140\tvalidation_1-logloss:0.368583\n",
      "[123]\tvalidation_0-logloss:0.368752\tvalidation_1-logloss:0.368219\n",
      "[124]\tvalidation_0-logloss:0.368363\tvalidation_1-logloss:0.367799\n",
      "[125]\tvalidation_0-logloss:0.367951\tvalidation_1-logloss:0.367445\n",
      "[126]\tvalidation_0-logloss:0.367612\tvalidation_1-logloss:0.367067\n",
      "[127]\tvalidation_0-logloss:0.367292\tvalidation_1-logloss:0.366776\n",
      "[128]\tvalidation_0-logloss:0.366892\tvalidation_1-logloss:0.366381\n",
      "[129]\tvalidation_0-logloss:0.366623\tvalidation_1-logloss:0.366081\n",
      "[130]\tvalidation_0-logloss:0.366193\tvalidation_1-logloss:0.365693\n",
      "[131]\tvalidation_0-logloss:0.365849\tvalidation_1-logloss:0.365323\n",
      "[132]\tvalidation_0-logloss:0.365490\tvalidation_1-logloss:0.364976\n",
      "[133]\tvalidation_0-logloss:0.365123\tvalidation_1-logloss:0.364625\n",
      "[134]\tvalidation_0-logloss:0.364831\tvalidation_1-logloss:0.364301\n",
      "[135]\tvalidation_0-logloss:0.364467\tvalidation_1-logloss:0.363957\n",
      "[136]\tvalidation_0-logloss:0.364132\tvalidation_1-logloss:0.363636\n",
      "[137]\tvalidation_0-logloss:0.363841\tvalidation_1-logloss:0.363313\n",
      "[138]\tvalidation_0-logloss:0.363477\tvalidation_1-logloss:0.362982\n",
      "[139]\tvalidation_0-logloss:0.363166\tvalidation_1-logloss:0.362682\n",
      "[140]\tvalidation_0-logloss:0.362884\tvalidation_1-logloss:0.362372\n",
      "[141]\tvalidation_0-logloss:0.362557\tvalidation_1-logloss:0.362080\n",
      "[142]\tvalidation_0-logloss:0.362256\tvalidation_1-logloss:0.361791\n",
      "[143]\tvalidation_0-logloss:0.362007\tvalidation_1-logloss:0.361509\n",
      "[144]\tvalidation_0-logloss:0.361725\tvalidation_1-logloss:0.361235\n",
      "[145]\tvalidation_0-logloss:0.361418\tvalidation_1-logloss:0.360957\n",
      "[146]\tvalidation_0-logloss:0.361141\tvalidation_1-logloss:0.360656\n",
      "[147]\tvalidation_0-logloss:0.360891\tvalidation_1-logloss:0.360381\n",
      "[148]\tvalidation_0-logloss:0.360603\tvalidation_1-logloss:0.360131\n",
      "[149]\tvalidation_0-logloss:0.360333\tvalidation_1-logloss:0.359875\n",
      "[150]\tvalidation_0-logloss:0.360162\tvalidation_1-logloss:0.359676\n",
      "[151]\tvalidation_0-logloss:0.359933\tvalidation_1-logloss:0.359430\n",
      "[152]\tvalidation_0-logloss:0.359691\tvalidation_1-logloss:0.359227\n",
      "[153]\tvalidation_0-logloss:0.359459\tvalidation_1-logloss:0.359004\n",
      "[154]\tvalidation_0-logloss:0.359241\tvalidation_1-logloss:0.358768\n",
      "[155]\tvalidation_0-logloss:0.359029\tvalidation_1-logloss:0.358547\n",
      "[156]\tvalidation_0-logloss:0.358810\tvalidation_1-logloss:0.358356\n",
      "[157]\tvalidation_0-logloss:0.358615\tvalidation_1-logloss:0.358171\n",
      "[158]\tvalidation_0-logloss:0.358374\tvalidation_1-logloss:0.357917\n",
      "[159]\tvalidation_0-logloss:0.358207\tvalidation_1-logloss:0.357728\n",
      "[160]\tvalidation_0-logloss:0.358029\tvalidation_1-logloss:0.357538\n",
      "[161]\tvalidation_0-logloss:0.357842\tvalidation_1-logloss:0.357382\n",
      "[162]\tvalidation_0-logloss:0.357626\tvalidation_1-logloss:0.357177\n",
      "[163]\tvalidation_0-logloss:0.357423\tvalidation_1-logloss:0.356975\n",
      "[164]\tvalidation_0-logloss:0.357227\tvalidation_1-logloss:0.356757\n",
      "[165]\tvalidation_0-logloss:0.357051\tvalidation_1-logloss:0.356569\n",
      "[166]\tvalidation_0-logloss:0.356838\tvalidation_1-logloss:0.356389\n",
      "[167]\tvalidation_0-logloss:0.356651\tvalidation_1-logloss:0.356223\n",
      "[168]\tvalidation_0-logloss:0.356505\tvalidation_1-logloss:0.356076\n",
      "[169]\tvalidation_0-logloss:0.356312\tvalidation_1-logloss:0.355871\n",
      "[170]\tvalidation_0-logloss:0.356139\tvalidation_1-logloss:0.355687\n",
      "[171]\tvalidation_0-logloss:0.355931\tvalidation_1-logloss:0.355481\n",
      "[172]\tvalidation_0-logloss:0.355736\tvalidation_1-logloss:0.355297\n",
      "[173]\tvalidation_0-logloss:0.355546\tvalidation_1-logloss:0.355120\n",
      "[174]\tvalidation_0-logloss:0.355399\tvalidation_1-logloss:0.354974\n",
      "[175]\tvalidation_0-logloss:0.355240\tvalidation_1-logloss:0.354802\n",
      "[176]\tvalidation_0-logloss:0.355103\tvalidation_1-logloss:0.354657\n",
      "[177]\tvalidation_0-logloss:0.354945\tvalidation_1-logloss:0.354488\n",
      "[178]\tvalidation_0-logloss:0.354746\tvalidation_1-logloss:0.354324\n",
      "[179]\tvalidation_0-logloss:0.354566\tvalidation_1-logloss:0.354158\n",
      "[180]\tvalidation_0-logloss:0.354409\tvalidation_1-logloss:0.354010\n",
      "[181]\tvalidation_0-logloss:0.354288\tvalidation_1-logloss:0.353884\n",
      "[182]\tvalidation_0-logloss:0.354148\tvalidation_1-logloss:0.353730\n",
      "[183]\tvalidation_0-logloss:0.354028\tvalidation_1-logloss:0.353608\n",
      "[184]\tvalidation_0-logloss:0.353871\tvalidation_1-logloss:0.353434\n",
      "[185]\tvalidation_0-logloss:0.353729\tvalidation_1-logloss:0.353318\n",
      "[186]\tvalidation_0-logloss:0.353572\tvalidation_1-logloss:0.353166\n",
      "[187]\tvalidation_0-logloss:0.353413\tvalidation_1-logloss:0.353021\n",
      "[188]\tvalidation_0-logloss:0.353314\tvalidation_1-logloss:0.352926\n",
      "[189]\tvalidation_0-logloss:0.353180\tvalidation_1-logloss:0.352784\n",
      "[190]\tvalidation_0-logloss:0.353055\tvalidation_1-logloss:0.352642\n",
      "[191]\tvalidation_0-logloss:0.352928\tvalidation_1-logloss:0.352507\n",
      "[192]\tvalidation_0-logloss:0.352838\tvalidation_1-logloss:0.352412\n",
      "[193]\tvalidation_0-logloss:0.352707\tvalidation_1-logloss:0.352274\n",
      "[194]\tvalidation_0-logloss:0.352563\tvalidation_1-logloss:0.352155\n",
      "[195]\tvalidation_0-logloss:0.352428\tvalidation_1-logloss:0.352025\n",
      "[196]\tvalidation_0-logloss:0.352307\tvalidation_1-logloss:0.351915\n",
      "[197]\tvalidation_0-logloss:0.352208\tvalidation_1-logloss:0.351817\n",
      "[198]\tvalidation_0-logloss:0.352087\tvalidation_1-logloss:0.351695\n",
      "[199]\tvalidation_0-logloss:0.351995\tvalidation_1-logloss:0.351593\n",
      "[200]\tvalidation_0-logloss:0.351889\tvalidation_1-logloss:0.351472\n",
      "[201]\tvalidation_0-logloss:0.351773\tvalidation_1-logloss:0.351361\n",
      "[202]\tvalidation_0-logloss:0.351667\tvalidation_1-logloss:0.351247\n",
      "[203]\tvalidation_0-logloss:0.351563\tvalidation_1-logloss:0.351133\n",
      "[204]\tvalidation_0-logloss:0.351433\tvalidation_1-logloss:0.351026\n",
      "[205]\tvalidation_0-logloss:0.351316\tvalidation_1-logloss:0.350919\n",
      "[206]\tvalidation_0-logloss:0.351219\tvalidation_1-logloss:0.350821\n",
      "[207]\tvalidation_0-logloss:0.351129\tvalidation_1-logloss:0.350742\n",
      "[208]\tvalidation_0-logloss:0.351029\tvalidation_1-logloss:0.350643\n",
      "[209]\tvalidation_0-logloss:0.350941\tvalidation_1-logloss:0.350551\n",
      "[210]\tvalidation_0-logloss:0.350859\tvalidation_1-logloss:0.350467\n",
      "[211]\tvalidation_0-logloss:0.350783\tvalidation_1-logloss:0.350384\n",
      "[212]\tvalidation_0-logloss:0.350703\tvalidation_1-logloss:0.350299\n",
      "[213]\tvalidation_0-logloss:0.350624\tvalidation_1-logloss:0.350224\n",
      "[214]\tvalidation_0-logloss:0.350543\tvalidation_1-logloss:0.350141\n",
      "[215]\tvalidation_0-logloss:0.350472\tvalidation_1-logloss:0.350066\n",
      "[216]\tvalidation_0-logloss:0.350397\tvalidation_1-logloss:0.349982\n",
      "[217]\tvalidation_0-logloss:0.350280\tvalidation_1-logloss:0.349896\n",
      "[218]\tvalidation_0-logloss:0.350196\tvalidation_1-logloss:0.349816\n",
      "[219]\tvalidation_0-logloss:0.350106\tvalidation_1-logloss:0.349735\n",
      "[220]\tvalidation_0-logloss:0.350034\tvalidation_1-logloss:0.349659\n",
      "[221]\tvalidation_0-logloss:0.349953\tvalidation_1-logloss:0.349588\n",
      "[222]\tvalidation_0-logloss:0.349879\tvalidation_1-logloss:0.349516\n",
      "[223]\tvalidation_0-logloss:0.349806\tvalidation_1-logloss:0.349441\n",
      "[224]\tvalidation_0-logloss:0.349735\tvalidation_1-logloss:0.349366\n",
      "[225]\tvalidation_0-logloss:0.349669\tvalidation_1-logloss:0.349297\n",
      "[226]\tvalidation_0-logloss:0.349610\tvalidation_1-logloss:0.349235\n",
      "[227]\tvalidation_0-logloss:0.349547\tvalidation_1-logloss:0.349165\n",
      "[228]\tvalidation_0-logloss:0.349487\tvalidation_1-logloss:0.349094\n",
      "[229]\tvalidation_0-logloss:0.349410\tvalidation_1-logloss:0.349022\n",
      "[230]\tvalidation_0-logloss:0.349330\tvalidation_1-logloss:0.348949\n",
      "[231]\tvalidation_0-logloss:0.349267\tvalidation_1-logloss:0.348883\n",
      "[232]\tvalidation_0-logloss:0.349197\tvalidation_1-logloss:0.348806\n",
      "[233]\tvalidation_0-logloss:0.349130\tvalidation_1-logloss:0.348730\n",
      "[234]\tvalidation_0-logloss:0.349057\tvalidation_1-logloss:0.348675\n",
      "[235]\tvalidation_0-logloss:0.348983\tvalidation_1-logloss:0.348619\n",
      "[236]\tvalidation_0-logloss:0.348908\tvalidation_1-logloss:0.348553\n",
      "[237]\tvalidation_0-logloss:0.348837\tvalidation_1-logloss:0.348484\n",
      "[238]\tvalidation_0-logloss:0.348759\tvalidation_1-logloss:0.348408\n",
      "[239]\tvalidation_0-logloss:0.348688\tvalidation_1-logloss:0.348340\n",
      "[240]\tvalidation_0-logloss:0.348621\tvalidation_1-logloss:0.348288\n",
      "[241]\tvalidation_0-logloss:0.348565\tvalidation_1-logloss:0.348239\n",
      "[242]\tvalidation_0-logloss:0.348502\tvalidation_1-logloss:0.348178\n",
      "[243]\tvalidation_0-logloss:0.348429\tvalidation_1-logloss:0.348102\n",
      "[244]\tvalidation_0-logloss:0.348359\tvalidation_1-logloss:0.348026\n",
      "[245]\tvalidation_0-logloss:0.348303\tvalidation_1-logloss:0.347972\n",
      "[246]\tvalidation_0-logloss:0.348249\tvalidation_1-logloss:0.347913\n",
      "[247]\tvalidation_0-logloss:0.348186\tvalidation_1-logloss:0.347845\n",
      "[248]\tvalidation_0-logloss:0.348114\tvalidation_1-logloss:0.347767\n",
      "[249]\tvalidation_0-logloss:0.348074\tvalidation_1-logloss:0.347726\n",
      "[250]\tvalidation_0-logloss:0.347993\tvalidation_1-logloss:0.347633\n",
      "[251]\tvalidation_0-logloss:0.347938\tvalidation_1-logloss:0.347573\n",
      "[252]\tvalidation_0-logloss:0.347894\tvalidation_1-logloss:0.347527\n",
      "[253]\tvalidation_0-logloss:0.347845\tvalidation_1-logloss:0.347487\n",
      "[254]\tvalidation_0-logloss:0.347783\tvalidation_1-logloss:0.347430\n",
      "[255]\tvalidation_0-logloss:0.347710\tvalidation_1-logloss:0.347358\n",
      "[256]\tvalidation_0-logloss:0.347660\tvalidation_1-logloss:0.347309\n",
      "[257]\tvalidation_0-logloss:0.347617\tvalidation_1-logloss:0.347266\n",
      "[258]\tvalidation_0-logloss:0.347577\tvalidation_1-logloss:0.347220\n",
      "[259]\tvalidation_0-logloss:0.347519\tvalidation_1-logloss:0.347162\n",
      "[260]\tvalidation_0-logloss:0.347474\tvalidation_1-logloss:0.347110\n",
      "[261]\tvalidation_0-logloss:0.347425\tvalidation_1-logloss:0.347085\n",
      "[262]\tvalidation_0-logloss:0.347360\tvalidation_1-logloss:0.347036\n",
      "[263]\tvalidation_0-logloss:0.347305\tvalidation_1-logloss:0.346993\n",
      "[264]\tvalidation_0-logloss:0.347239\tvalidation_1-logloss:0.346932\n",
      "[265]\tvalidation_0-logloss:0.347187\tvalidation_1-logloss:0.346887\n",
      "[266]\tvalidation_0-logloss:0.347145\tvalidation_1-logloss:0.346845\n",
      "[267]\tvalidation_0-logloss:0.347104\tvalidation_1-logloss:0.346805\n",
      "[268]\tvalidation_0-logloss:0.347049\tvalidation_1-logloss:0.346748\n",
      "[269]\tvalidation_0-logloss:0.347009\tvalidation_1-logloss:0.346702\n",
      "[270]\tvalidation_0-logloss:0.346967\tvalidation_1-logloss:0.346667\n",
      "[271]\tvalidation_0-logloss:0.346917\tvalidation_1-logloss:0.346626\n",
      "[272]\tvalidation_0-logloss:0.346864\tvalidation_1-logloss:0.346577\n",
      "[273]\tvalidation_0-logloss:0.346824\tvalidation_1-logloss:0.346541\n",
      "[274]\tvalidation_0-logloss:0.346771\tvalidation_1-logloss:0.346489\n",
      "[275]\tvalidation_0-logloss:0.346720\tvalidation_1-logloss:0.346434\n",
      "[276]\tvalidation_0-logloss:0.346683\tvalidation_1-logloss:0.346395\n",
      "[277]\tvalidation_0-logloss:0.346644\tvalidation_1-logloss:0.346350\n",
      "[278]\tvalidation_0-logloss:0.346590\tvalidation_1-logloss:0.346289\n",
      "[279]\tvalidation_0-logloss:0.346528\tvalidation_1-logloss:0.346221\n",
      "[280]\tvalidation_0-logloss:0.346495\tvalidation_1-logloss:0.346186\n",
      "[281]\tvalidation_0-logloss:0.346467\tvalidation_1-logloss:0.346163\n",
      "[282]\tvalidation_0-logloss:0.346438\tvalidation_1-logloss:0.346132\n",
      "[283]\tvalidation_0-logloss:0.346410\tvalidation_1-logloss:0.346106\n",
      "[284]\tvalidation_0-logloss:0.346363\tvalidation_1-logloss:0.346055\n",
      "[285]\tvalidation_0-logloss:0.346308\tvalidation_1-logloss:0.346003\n",
      "[286]\tvalidation_0-logloss:0.346257\tvalidation_1-logloss:0.345950\n",
      "[287]\tvalidation_0-logloss:0.346228\tvalidation_1-logloss:0.345922\n",
      "[288]\tvalidation_0-logloss:0.346197\tvalidation_1-logloss:0.345891\n",
      "[289]\tvalidation_0-logloss:0.346162\tvalidation_1-logloss:0.345846\n",
      "[290]\tvalidation_0-logloss:0.346118\tvalidation_1-logloss:0.345802\n",
      "[291]\tvalidation_0-logloss:0.346084\tvalidation_1-logloss:0.345768\n",
      "[292]\tvalidation_0-logloss:0.346042\tvalidation_1-logloss:0.345724\n",
      "[293]\tvalidation_0-logloss:0.345995\tvalidation_1-logloss:0.345676\n",
      "[294]\tvalidation_0-logloss:0.345952\tvalidation_1-logloss:0.345639\n",
      "[295]\tvalidation_0-logloss:0.345913\tvalidation_1-logloss:0.345601\n",
      "[296]\tvalidation_0-logloss:0.345871\tvalidation_1-logloss:0.345563\n",
      "[297]\tvalidation_0-logloss:0.345805\tvalidation_1-logloss:0.345496\n",
      "[298]\tvalidation_0-logloss:0.345746\tvalidation_1-logloss:0.345446\n",
      "[299]\tvalidation_0-logloss:0.345706\tvalidation_1-logloss:0.345414\n",
      "[300]\tvalidation_0-logloss:0.345678\tvalidation_1-logloss:0.345389\n",
      "[301]\tvalidation_0-logloss:0.345642\tvalidation_1-logloss:0.345358\n",
      "[302]\tvalidation_0-logloss:0.345598\tvalidation_1-logloss:0.345318\n",
      "[303]\tvalidation_0-logloss:0.345574\tvalidation_1-logloss:0.345294\n",
      "[304]\tvalidation_0-logloss:0.345552\tvalidation_1-logloss:0.345274\n",
      "[305]\tvalidation_0-logloss:0.345514\tvalidation_1-logloss:0.345241\n",
      "[306]\tvalidation_0-logloss:0.345484\tvalidation_1-logloss:0.345215\n",
      "[307]\tvalidation_0-logloss:0.345464\tvalidation_1-logloss:0.345195\n",
      "[308]\tvalidation_0-logloss:0.345433\tvalidation_1-logloss:0.345164\n",
      "[309]\tvalidation_0-logloss:0.345400\tvalidation_1-logloss:0.345123\n",
      "[310]\tvalidation_0-logloss:0.345357\tvalidation_1-logloss:0.345083\n",
      "[311]\tvalidation_0-logloss:0.345329\tvalidation_1-logloss:0.345055\n",
      "[312]\tvalidation_0-logloss:0.345265\tvalidation_1-logloss:0.344993\n",
      "[313]\tvalidation_0-logloss:0.345225\tvalidation_1-logloss:0.344947\n",
      "[314]\tvalidation_0-logloss:0.345194\tvalidation_1-logloss:0.344917\n",
      "[315]\tvalidation_0-logloss:0.345156\tvalidation_1-logloss:0.344877\n",
      "[316]\tvalidation_0-logloss:0.345132\tvalidation_1-logloss:0.344853\n",
      "[317]\tvalidation_0-logloss:0.345105\tvalidation_1-logloss:0.344825\n",
      "[318]\tvalidation_0-logloss:0.345045\tvalidation_1-logloss:0.344767\n",
      "[319]\tvalidation_0-logloss:0.345001\tvalidation_1-logloss:0.344722\n",
      "[320]\tvalidation_0-logloss:0.344973\tvalidation_1-logloss:0.344695\n",
      "[321]\tvalidation_0-logloss:0.344945\tvalidation_1-logloss:0.344668\n",
      "[322]\tvalidation_0-logloss:0.344899\tvalidation_1-logloss:0.344626\n",
      "[323]\tvalidation_0-logloss:0.344859\tvalidation_1-logloss:0.344600\n",
      "[324]\tvalidation_0-logloss:0.344812\tvalidation_1-logloss:0.344562\n",
      "[325]\tvalidation_0-logloss:0.344778\tvalidation_1-logloss:0.344542\n",
      "[326]\tvalidation_0-logloss:0.344733\tvalidation_1-logloss:0.344499\n",
      "[327]\tvalidation_0-logloss:0.344689\tvalidation_1-logloss:0.344464\n",
      "[328]\tvalidation_0-logloss:0.344648\tvalidation_1-logloss:0.344426\n",
      "[329]\tvalidation_0-logloss:0.344623\tvalidation_1-logloss:0.344406\n",
      "[330]\tvalidation_0-logloss:0.344602\tvalidation_1-logloss:0.344391\n",
      "[331]\tvalidation_0-logloss:0.344559\tvalidation_1-logloss:0.344347\n",
      "[332]\tvalidation_0-logloss:0.344519\tvalidation_1-logloss:0.344306\n",
      "[333]\tvalidation_0-logloss:0.344480\tvalidation_1-logloss:0.344270\n",
      "[334]\tvalidation_0-logloss:0.344459\tvalidation_1-logloss:0.344252\n",
      "[335]\tvalidation_0-logloss:0.344395\tvalidation_1-logloss:0.344191\n",
      "[336]\tvalidation_0-logloss:0.344359\tvalidation_1-logloss:0.344160\n",
      "[337]\tvalidation_0-logloss:0.344339\tvalidation_1-logloss:0.344144\n",
      "[338]\tvalidation_0-logloss:0.344305\tvalidation_1-logloss:0.344116\n",
      "[339]\tvalidation_0-logloss:0.344239\tvalidation_1-logloss:0.344057\n",
      "[340]\tvalidation_0-logloss:0.344203\tvalidation_1-logloss:0.344021\n",
      "[341]\tvalidation_0-logloss:0.344172\tvalidation_1-logloss:0.343993\n",
      "[342]\tvalidation_0-logloss:0.344150\tvalidation_1-logloss:0.343971\n",
      "[343]\tvalidation_0-logloss:0.344082\tvalidation_1-logloss:0.343903\n",
      "[344]\tvalidation_0-logloss:0.344043\tvalidation_1-logloss:0.343862\n",
      "[345]\tvalidation_0-logloss:0.344010\tvalidation_1-logloss:0.343831\n",
      "[346]\tvalidation_0-logloss:0.343985\tvalidation_1-logloss:0.343807\n",
      "[347]\tvalidation_0-logloss:0.343955\tvalidation_1-logloss:0.343781\n",
      "[348]\tvalidation_0-logloss:0.343931\tvalidation_1-logloss:0.343759\n",
      "[349]\tvalidation_0-logloss:0.343901\tvalidation_1-logloss:0.343732\n",
      "[350]\tvalidation_0-logloss:0.343874\tvalidation_1-logloss:0.343705\n",
      "[351]\tvalidation_0-logloss:0.343850\tvalidation_1-logloss:0.343683\n",
      "[352]\tvalidation_0-logloss:0.343811\tvalidation_1-logloss:0.343644\n",
      "[353]\tvalidation_0-logloss:0.343779\tvalidation_1-logloss:0.343613\n",
      "[354]\tvalidation_0-logloss:0.343731\tvalidation_1-logloss:0.343566\n",
      "[355]\tvalidation_0-logloss:0.343681\tvalidation_1-logloss:0.343516\n",
      "[356]\tvalidation_0-logloss:0.343628\tvalidation_1-logloss:0.343464\n",
      "[357]\tvalidation_0-logloss:0.343594\tvalidation_1-logloss:0.343431\n",
      "[358]\tvalidation_0-logloss:0.343567\tvalidation_1-logloss:0.343407\n",
      "[359]\tvalidation_0-logloss:0.343549\tvalidation_1-logloss:0.343394\n",
      "[360]\tvalidation_0-logloss:0.343504\tvalidation_1-logloss:0.343352\n",
      "[361]\tvalidation_0-logloss:0.343487\tvalidation_1-logloss:0.343337\n",
      "[362]\tvalidation_0-logloss:0.343456\tvalidation_1-logloss:0.343309\n",
      "[363]\tvalidation_0-logloss:0.343418\tvalidation_1-logloss:0.343272\n",
      "[364]\tvalidation_0-logloss:0.343383\tvalidation_1-logloss:0.343240\n",
      "[365]\tvalidation_0-logloss:0.343353\tvalidation_1-logloss:0.343213\n",
      "[366]\tvalidation_0-logloss:0.343315\tvalidation_1-logloss:0.343177\n",
      "[367]\tvalidation_0-logloss:0.343287\tvalidation_1-logloss:0.343153\n",
      "[368]\tvalidation_0-logloss:0.343256\tvalidation_1-logloss:0.343120\n",
      "[369]\tvalidation_0-logloss:0.343230\tvalidation_1-logloss:0.343092\n",
      "[370]\tvalidation_0-logloss:0.343190\tvalidation_1-logloss:0.343053\n",
      "[371]\tvalidation_0-logloss:0.343146\tvalidation_1-logloss:0.343010\n",
      "[372]\tvalidation_0-logloss:0.343091\tvalidation_1-logloss:0.342955\n",
      "[373]\tvalidation_0-logloss:0.343064\tvalidation_1-logloss:0.342931\n",
      "[374]\tvalidation_0-logloss:0.343008\tvalidation_1-logloss:0.342872\n",
      "[375]\tvalidation_0-logloss:0.342965\tvalidation_1-logloss:0.342834\n",
      "[376]\tvalidation_0-logloss:0.342930\tvalidation_1-logloss:0.342801\n",
      "[377]\tvalidation_0-logloss:0.342910\tvalidation_1-logloss:0.342785\n",
      "[378]\tvalidation_0-logloss:0.342873\tvalidation_1-logloss:0.342752\n",
      "[379]\tvalidation_0-logloss:0.342839\tvalidation_1-logloss:0.342724\n",
      "[380]\tvalidation_0-logloss:0.342813\tvalidation_1-logloss:0.342703\n",
      "[381]\tvalidation_0-logloss:0.342789\tvalidation_1-logloss:0.342685\n",
      "[382]\tvalidation_0-logloss:0.342759\tvalidation_1-logloss:0.342660\n",
      "[383]\tvalidation_0-logloss:0.342719\tvalidation_1-logloss:0.342625\n",
      "[384]\tvalidation_0-logloss:0.342691\tvalidation_1-logloss:0.342605\n",
      "[385]\tvalidation_0-logloss:0.342654\tvalidation_1-logloss:0.342571\n",
      "[386]\tvalidation_0-logloss:0.342632\tvalidation_1-logloss:0.342552\n",
      "[387]\tvalidation_0-logloss:0.342588\tvalidation_1-logloss:0.342516\n",
      "[388]\tvalidation_0-logloss:0.342565\tvalidation_1-logloss:0.342498\n",
      "[389]\tvalidation_0-logloss:0.342539\tvalidation_1-logloss:0.342474\n",
      "[390]\tvalidation_0-logloss:0.342506\tvalidation_1-logloss:0.342442\n",
      "[391]\tvalidation_0-logloss:0.342476\tvalidation_1-logloss:0.342418\n",
      "[392]\tvalidation_0-logloss:0.342437\tvalidation_1-logloss:0.342381\n",
      "[393]\tvalidation_0-logloss:0.342393\tvalidation_1-logloss:0.342336\n",
      "[394]\tvalidation_0-logloss:0.342363\tvalidation_1-logloss:0.342310\n",
      "[395]\tvalidation_0-logloss:0.342332\tvalidation_1-logloss:0.342283\n",
      "[396]\tvalidation_0-logloss:0.342286\tvalidation_1-logloss:0.342240\n",
      "[397]\tvalidation_0-logloss:0.342257\tvalidation_1-logloss:0.342212\n",
      "[398]\tvalidation_0-logloss:0.342234\tvalidation_1-logloss:0.342191\n",
      "[399]\tvalidation_0-logloss:0.342217\tvalidation_1-logloss:0.342173\n",
      "[400]\tvalidation_0-logloss:0.342179\tvalidation_1-logloss:0.342138\n",
      "[401]\tvalidation_0-logloss:0.342159\tvalidation_1-logloss:0.342122\n",
      "[402]\tvalidation_0-logloss:0.342146\tvalidation_1-logloss:0.342113\n",
      "[403]\tvalidation_0-logloss:0.342103\tvalidation_1-logloss:0.342075\n",
      "[404]\tvalidation_0-logloss:0.342065\tvalidation_1-logloss:0.342037\n",
      "[405]\tvalidation_0-logloss:0.342036\tvalidation_1-logloss:0.342009\n",
      "[406]\tvalidation_0-logloss:0.342011\tvalidation_1-logloss:0.341988\n",
      "[407]\tvalidation_0-logloss:0.341975\tvalidation_1-logloss:0.341960\n",
      "[408]\tvalidation_0-logloss:0.341945\tvalidation_1-logloss:0.341933\n",
      "[409]\tvalidation_0-logloss:0.341926\tvalidation_1-logloss:0.341917\n",
      "[410]\tvalidation_0-logloss:0.341897\tvalidation_1-logloss:0.341893\n",
      "[411]\tvalidation_0-logloss:0.341874\tvalidation_1-logloss:0.341874\n",
      "[412]\tvalidation_0-logloss:0.341848\tvalidation_1-logloss:0.341851\n",
      "[413]\tvalidation_0-logloss:0.341808\tvalidation_1-logloss:0.341812\n",
      "[414]\tvalidation_0-logloss:0.341759\tvalidation_1-logloss:0.341761\n",
      "[415]\tvalidation_0-logloss:0.341743\tvalidation_1-logloss:0.341745\n",
      "[416]\tvalidation_0-logloss:0.341715\tvalidation_1-logloss:0.341721\n",
      "[417]\tvalidation_0-logloss:0.341689\tvalidation_1-logloss:0.341698\n",
      "[418]\tvalidation_0-logloss:0.341669\tvalidation_1-logloss:0.341679\n",
      "[419]\tvalidation_0-logloss:0.341645\tvalidation_1-logloss:0.341659\n",
      "[420]\tvalidation_0-logloss:0.341618\tvalidation_1-logloss:0.341633\n",
      "[421]\tvalidation_0-logloss:0.341601\tvalidation_1-logloss:0.341619\n",
      "[422]\tvalidation_0-logloss:0.341574\tvalidation_1-logloss:0.341591\n",
      "[423]\tvalidation_0-logloss:0.341539\tvalidation_1-logloss:0.341558\n",
      "[424]\tvalidation_0-logloss:0.341485\tvalidation_1-logloss:0.341507\n",
      "[425]\tvalidation_0-logloss:0.341455\tvalidation_1-logloss:0.341478\n",
      "[426]\tvalidation_0-logloss:0.341401\tvalidation_1-logloss:0.341426\n",
      "[427]\tvalidation_0-logloss:0.341388\tvalidation_1-logloss:0.341417\n",
      "[428]\tvalidation_0-logloss:0.341353\tvalidation_1-logloss:0.341381\n",
      "[429]\tvalidation_0-logloss:0.341319\tvalidation_1-logloss:0.341352\n",
      "[430]\tvalidation_0-logloss:0.341301\tvalidation_1-logloss:0.341333\n",
      "[431]\tvalidation_0-logloss:0.341275\tvalidation_1-logloss:0.341311\n",
      "[432]\tvalidation_0-logloss:0.341251\tvalidation_1-logloss:0.341291\n",
      "[433]\tvalidation_0-logloss:0.341215\tvalidation_1-logloss:0.341257\n",
      "[434]\tvalidation_0-logloss:0.341176\tvalidation_1-logloss:0.341221\n",
      "[435]\tvalidation_0-logloss:0.341150\tvalidation_1-logloss:0.341198\n",
      "[436]\tvalidation_0-logloss:0.341130\tvalidation_1-logloss:0.341183\n",
      "[437]\tvalidation_0-logloss:0.341095\tvalidation_1-logloss:0.341155\n",
      "[438]\tvalidation_0-logloss:0.341072\tvalidation_1-logloss:0.341130\n",
      "[439]\tvalidation_0-logloss:0.341043\tvalidation_1-logloss:0.341099\n",
      "[440]\tvalidation_0-logloss:0.340991\tvalidation_1-logloss:0.341047\n",
      "[441]\tvalidation_0-logloss:0.340967\tvalidation_1-logloss:0.341026\n",
      "[442]\tvalidation_0-logloss:0.340929\tvalidation_1-logloss:0.340990\n",
      "[443]\tvalidation_0-logloss:0.340918\tvalidation_1-logloss:0.340979\n",
      "[444]\tvalidation_0-logloss:0.340906\tvalidation_1-logloss:0.340971\n",
      "[445]\tvalidation_0-logloss:0.340884\tvalidation_1-logloss:0.340952\n",
      "[446]\tvalidation_0-logloss:0.340873\tvalidation_1-logloss:0.340942\n",
      "[447]\tvalidation_0-logloss:0.340845\tvalidation_1-logloss:0.340917\n",
      "[448]\tvalidation_0-logloss:0.340796\tvalidation_1-logloss:0.340867\n",
      "[449]\tvalidation_0-logloss:0.340772\tvalidation_1-logloss:0.340845\n",
      "[450]\tvalidation_0-logloss:0.340753\tvalidation_1-logloss:0.340828\n",
      "[451]\tvalidation_0-logloss:0.340731\tvalidation_1-logloss:0.340806\n",
      "[452]\tvalidation_0-logloss:0.340714\tvalidation_1-logloss:0.340792\n",
      "[453]\tvalidation_0-logloss:0.340701\tvalidation_1-logloss:0.340783\n",
      "[454]\tvalidation_0-logloss:0.340666\tvalidation_1-logloss:0.340753\n",
      "[455]\tvalidation_0-logloss:0.340625\tvalidation_1-logloss:0.340711\n",
      "[456]\tvalidation_0-logloss:0.340602\tvalidation_1-logloss:0.340688\n",
      "[457]\tvalidation_0-logloss:0.340565\tvalidation_1-logloss:0.340652\n",
      "[458]\tvalidation_0-logloss:0.340547\tvalidation_1-logloss:0.340635\n",
      "[459]\tvalidation_0-logloss:0.340533\tvalidation_1-logloss:0.340623\n",
      "[460]\tvalidation_0-logloss:0.340513\tvalidation_1-logloss:0.340604\n",
      "[461]\tvalidation_0-logloss:0.340454\tvalidation_1-logloss:0.340550\n",
      "[462]\tvalidation_0-logloss:0.340441\tvalidation_1-logloss:0.340540\n",
      "[463]\tvalidation_0-logloss:0.340421\tvalidation_1-logloss:0.340521\n",
      "[464]\tvalidation_0-logloss:0.340383\tvalidation_1-logloss:0.340489\n",
      "[465]\tvalidation_0-logloss:0.340361\tvalidation_1-logloss:0.340470\n",
      "[466]\tvalidation_0-logloss:0.340330\tvalidation_1-logloss:0.340442\n",
      "[467]\tvalidation_0-logloss:0.340322\tvalidation_1-logloss:0.340436\n",
      "[468]\tvalidation_0-logloss:0.340288\tvalidation_1-logloss:0.340400\n",
      "[469]\tvalidation_0-logloss:0.340266\tvalidation_1-logloss:0.340378\n",
      "[470]\tvalidation_0-logloss:0.340247\tvalidation_1-logloss:0.340364\n",
      "[471]\tvalidation_0-logloss:0.340230\tvalidation_1-logloss:0.340350\n",
      "[472]\tvalidation_0-logloss:0.340222\tvalidation_1-logloss:0.340344\n",
      "[473]\tvalidation_0-logloss:0.340189\tvalidation_1-logloss:0.340318\n",
      "[474]\tvalidation_0-logloss:0.340177\tvalidation_1-logloss:0.340311\n",
      "[475]\tvalidation_0-logloss:0.340151\tvalidation_1-logloss:0.340290\n",
      "[476]\tvalidation_0-logloss:0.340127\tvalidation_1-logloss:0.340267\n",
      "[477]\tvalidation_0-logloss:0.340110\tvalidation_1-logloss:0.340252\n",
      "[478]\tvalidation_0-logloss:0.340064\tvalidation_1-logloss:0.340206\n",
      "[479]\tvalidation_0-logloss:0.340038\tvalidation_1-logloss:0.340182\n",
      "[480]\tvalidation_0-logloss:0.340024\tvalidation_1-logloss:0.340172\n",
      "[481]\tvalidation_0-logloss:0.339995\tvalidation_1-logloss:0.340149\n",
      "[482]\tvalidation_0-logloss:0.339980\tvalidation_1-logloss:0.340135\n",
      "[483]\tvalidation_0-logloss:0.339967\tvalidation_1-logloss:0.340123\n",
      "[484]\tvalidation_0-logloss:0.339936\tvalidation_1-logloss:0.340097\n",
      "[485]\tvalidation_0-logloss:0.339922\tvalidation_1-logloss:0.340086\n",
      "[486]\tvalidation_0-logloss:0.339895\tvalidation_1-logloss:0.340063\n",
      "[487]\tvalidation_0-logloss:0.339842\tvalidation_1-logloss:0.340009\n",
      "[488]\tvalidation_0-logloss:0.339823\tvalidation_1-logloss:0.339993\n",
      "[489]\tvalidation_0-logloss:0.339798\tvalidation_1-logloss:0.339968\n",
      "[490]\tvalidation_0-logloss:0.339784\tvalidation_1-logloss:0.339957\n",
      "[491]\tvalidation_0-logloss:0.339741\tvalidation_1-logloss:0.339916\n",
      "[492]\tvalidation_0-logloss:0.339731\tvalidation_1-logloss:0.339909\n",
      "[493]\tvalidation_0-logloss:0.339720\tvalidation_1-logloss:0.339901\n",
      "[494]\tvalidation_0-logloss:0.339709\tvalidation_1-logloss:0.339892\n",
      "[495]\tvalidation_0-logloss:0.339686\tvalidation_1-logloss:0.339870\n",
      "[496]\tvalidation_0-logloss:0.339674\tvalidation_1-logloss:0.339857\n",
      "[497]\tvalidation_0-logloss:0.339657\tvalidation_1-logloss:0.339842\n",
      "[498]\tvalidation_0-logloss:0.339641\tvalidation_1-logloss:0.339830\n",
      "[499]\tvalidation_0-logloss:0.339631\tvalidation_1-logloss:0.339823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0.5, learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = RandomForestClassifier(n_estimators=150, n_jobs=8)   # 0.39680 (on public)\n",
    "#model = ExtraTreesClassifier(n_estimators=62, n_jobs=8) # 0.48183 (on public)\n",
    "#model = AdaBoostClassifier()\n",
    "#model = GradientBoostingClassifier(n_estimators=500, max_depth=4, learning_rate=0.2, subsample=0.7) # 0.34721 (on public)\n",
    "#model = KNeighborsClassifier(n_neighbors=25)\n",
    "#model = MultinomialNB() # 0.57\n",
    "#model = SVC()\n",
    "\n",
    "model = XGBClassifier(n_estimators=500, learning_rate=0.02, max_depth=4, subsample=0.7, gamma=0.5, seed=42,\n",
    "            colsample_bytree=0.7) # 0.34785 (on public)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_vald, y_vald)],\n",
    "          early_stopping_rounds=50, verbose=True, eval_metric='logloss')\n",
    "\n",
    "\n",
    "#model = VotingClassifier(estimators=[('xgb', xgb), ('knn', knn), ('rf', rf)],\n",
    "#                        voting='soft', weights=[4.5, 1.1, 1.2])\n",
    "\n",
    "#model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.19921649959672774\n",
      "Acc: 0.8219067508872632\n",
      "Precision: 0.6928471248246845\n",
      "Recall: 0.11633305298570228\n",
      "LogLoss: 0.3398170983777008\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_vald)\n",
    "val_prob_predictions = model.predict_proba(X_vald)\n",
    "\n",
    "for metric_name, metric_func in zip(\n",
    "    ['F1-score', 'Acc', 'Precision', 'Recall', 'LogLoss'],\n",
    "    [f1_score, accuracy_score, precision_score, recall_score, log_loss]\n",
    "):\n",
    "    \n",
    "    val_predictions = val_predictions if metric_name not in ['LogLoss'] else val_prob_predictions\n",
    "    metric_score = metric_func(y_vald, val_predictions)\n",
    "    print('{0}: {1}'.format(metric_name, metric_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=8,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del X, y, X_train, y_train, X_vald, y_vald\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    'submission.csv', np.c_[range(len(predictions)), predictions[:,1]],\n",
    "    delimiter=',', header='test_id,is_duplicate', comments='', fmt='%d,%f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w', buffering=1) as submission_file:\n",
    "    submission_file.write('test_id,is_duplicate')\n",
    "    \n",
    "    for test_id, test_row in enumerate(X_test.iterrows()):\n",
    "        row_prediction = model.predict_proba(X_test[test_id:])\n",
    "        submission_file.write('%d,%f' % test_id, row_prediction[:,1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
